{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9767724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee70d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load valid projects from valid_projects.txt\n",
    "valid_projects = []\n",
    "with open('valid_project.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        project = line.strip()\n",
    "        if project:  # Ignore empty lines\n",
    "            valid_projects.append(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d679290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CERV-2025-CHILD',\n",
       " 'CERV-2025-CITIZENS-CIV',\n",
       " 'CERV-2025-DAPHNE',\n",
       " 'Connecting_Spheres',\n",
       " 'COPILOT',\n",
       " 'CREA-CROSS-2025-INNOVLAB',\n",
       " 'CREA-MEDIA-2025-CINNET',\n",
       " 'CREA-MEDIA-2025-FILMDIST',\n",
       " 'CREA-MEDIA-2025-FILMOVE',\n",
       " 'CREA-MEDIA-2025-TRAINING',\n",
       " 'CREA-MEDIA-2025-TVONLINE',\n",
       " 'DigiQ',\n",
       " 'DIGITAL-2025-EDIH-EU-EEA-08-CONSOLIDATION-STEP',\n",
       " 'E-BOOST',\n",
       " 'EDF-2025-CSA-NFP',\n",
       " 'EDF-2025-LS-DA-SME-NT',\n",
       " 'EDF-2025-LS-RA-SMERO-NT',\n",
       " 'EP-LINC-SUBV-2025-CONF-INT-01',\n",
       " 'EP-LINC-SUBV-2025-CONF-INT-02',\n",
       " 'EP-LINC-SUBV-2025-CONF-INT-03',\n",
       " 'ERA4Health',\n",
       " 'ERASMUS-EDU-2022-ECHE-CERT-FP',\n",
       " 'ERASMUS-EDU-2025-CSC-OG-FPA',\n",
       " 'ERASMUS-EDU-2025-PEX-COVE',\n",
       " 'ERASMUS-YOUTH-2025-CSC-OG-FPA',\n",
       " 'ERC-2025-POC',\n",
       " 'ESC-HUMAID-2021-QUAL-LABEL-FP',\n",
       " 'ESC-HUMAID-2025-VOLUN',\n",
       " 'ESF-2025-AG-NETW-MF-SE',\n",
       " 'ESF-2025-EURES-CBC',\n",
       " 'ESF-2025-OG-NETW-NGO-FPA',\n",
       " 'ESF-2025-OG-NETW-NGO-SGA',\n",
       " 'EUBA-EFSA-2025-PREV-02',\n",
       " 'FABRIX',\n",
       " 'FRONTIERS',\n",
       " 'HORIZON-EIC-2025-ACCELERATOR-01',\n",
       " 'HORIZON-EIC-2025-EICSTEP-01',\n",
       " 'HORIZON-JU-CBE-2025-CSA-01',\n",
       " 'HORIZON-JU-CBE-2025-IAFlag-03',\n",
       " 'HORIZON-JU-CBE-2025-RIA-02',\n",
       " 'HORIZON-JU-CLEANH2-2025-01-03',\n",
       " 'HORIZON-JU-CLEANH2-2025-01-06',\n",
       " 'HORIZON-JU-CLEANH2-2025-02-01',\n",
       " 'HORIZON-JU-IHI-2025-09-01-single-stage',\n",
       " 'HORIZON-MSCA-2025-COFUND-01-01',\n",
       " 'HORIZON-SESAR-2025-DES-ER-03-WA1-1',\n",
       " 'INNOVFUND-2024-BATT-EV-CELLS',\n",
       " 'JUST-2025-JCOO',\n",
       " 'JUST-2025-JCOO-JACC-OG-FPA',\n",
       " 'JUST-2025-JCOO-JACC-OG-SGA',\n",
       " 'NGI0_Commons_Fund',\n",
       " 'OSCARS',\n",
       " 'PERI-2025-ANTI-COUNTERFEIT',\n",
       " 'PPPA-2025-COUNSEL',\n",
       " 'PPPA-2025-DEPLAN',\n",
       " 'RFCS-2025-CSP',\n",
       " 'RFCS-2025-JT',\n",
       " 'SMP-CONS-2025-ADR-RAD',\n",
       " 'SOCPL-2025-INFO-WK',\n",
       " 'UCPM-2025-KAPP-EX',\n",
       " 'UCPM-2025-KAPP-PVPP',\n",
       " 'UCPM-2025-TRACK1',\n",
       " 'Ukraine-Ready4EU',\n",
       " 'UP-RISE']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1643e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import types\n",
    "import time  # Added for retry logic\n",
    "\n",
    "# Nastav API klíč (ujisti se, že máš ve svém prostředí proměnnou GOOGLE_API_KEY)\n",
    "genai.configure(api_key=\"AIzaSyB3LkpREqIq8WwCFxsjXEd6-2h-Jnu1G7U\")\n",
    "\n",
    "\n",
    "def generate(input: str, questions:str, max_retries=5):\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following text about a European Project Call answer to each question. Output must be in same JSON format. Each answer must be only a number!\n",
    "\n",
    "    Text:\n",
    "    {input}\n",
    "\n",
    "    Questions:\n",
    "    {questions}\n",
    "    \"\"\"\n",
    "\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            # Najdi první a poslední složenou závorku a zkus to zparsovat\n",
    "            json_start = response.text.find('{')\n",
    "            json_end = response.text.rfind('}') + 1\n",
    "            json_str = response.text[json_start:json_end]\n",
    "            parsed = json.loads(json_str)\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            wait_time = 2 ** retries  # Exponential backoff\n",
    "            print(f\"Retry {retries}/{max_retries} after error: {e}. Waiting {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "    print(\"Max retries reached. Returning None.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edbecae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document chunked into 589 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.6000\n",
      "Document chunked into 579 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 9 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.7000\n",
      "Document chunked into 727 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.6333\n",
      "Document chunked into 5 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 1 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.7000\n",
      "Document chunked into 7 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 4 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.7400\n",
      "Document chunked into 591 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.7500\n",
      "Document chunked into 591 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 8 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.7286\n",
      "Document chunked into 593 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.7125\n",
      "Document chunked into 592 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 4 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.7444\n",
      "Document chunked into 590 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.7200\n",
      "Document chunked into 653 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.7273\n",
      "Document chunked into 8 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.7333\n",
      "Document chunked into 243 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.7231\n",
      "Document chunked into 11 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 3 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.7286\n",
      "Document chunked into 674 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.7133\n",
      "Document chunked into 771 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 8 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.7125\n",
      "Document chunked into 767 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.7000\n",
      "Document chunked into 308 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.7111\n",
      "Document chunked into 304 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.7053\n",
      "Document chunked into 307 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.7100\n",
      "Document chunked into 67 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 1 relevant chunks\n",
      "Correct answers: 0/10\n",
      "Current average score: 0.6762\n",
      "Document chunked into 18 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.6864\n",
      "Document chunked into 514 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6870\n",
      "Document chunked into 599 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 2 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.6958\n",
      "Document chunked into 512 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.7000\n",
      "Document chunked into 913 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.6923\n",
      "Document chunked into 107 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 3/10\n",
      "Current average score: 0.6778\n",
      "Document chunked into 735 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6786\n",
      "Document chunked into 657 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 8 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.6724\n",
      "Document chunked into 656 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 2/10\n",
      "Current average score: 0.6567\n",
      "Document chunked into 510 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.6645\n",
      "Document chunked into 576 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 8 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.6719\n",
      "Document chunked into 627 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 9 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.6697\n",
      "Document chunked into 11 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 3 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6706\n",
      "Document chunked into 5 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 2 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.6771\n",
      "Document chunked into 291 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.6722\n",
      "Document chunked into 188 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 8 relevant chunks\n",
      "Correct answers: 4/10\n",
      "Current average score: 0.6649\n",
      "Document chunked into 1134 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 10 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.6605\n",
      "Document chunked into 1206 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 9 relevant chunks\n",
      "Correct answers: 3/10\n",
      "Current average score: 0.6513\n",
      "Document chunked into 1148 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 9 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6525\n",
      "Document chunked into 907 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 2/10\n",
      "Current average score: 0.6415\n",
      "Document chunked into 832 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.6381\n",
      "Document chunked into 169 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.6442\n",
      "Document chunked into 527 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6455\n",
      "Document chunked into 593 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.6489\n",
      "Document chunked into 1 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 1 relevant chunks\n",
      "Correct answers: 1/1\n",
      "Current average score: 0.6565\n",
      "Document chunked into 130 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 3 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6574\n",
      "Document chunked into 570 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 10 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.6562\n",
      "Document chunked into 567 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6571\n",
      "Document chunked into 134 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.6640\n",
      "Document chunked into 780 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6647\n",
      "Document chunked into 664 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 6 relevant chunks\n",
      "Correct answers: 3/10\n",
      "Current average score: 0.6577\n",
      "Document chunked into 575 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.6566\n",
      "Document chunked into 581 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6574\n",
      "Document chunked into 687 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 3/10\n",
      "Current average score: 0.6509\n",
      "Document chunked into 671 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 8 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.6500\n",
      "Document chunked into 659 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 4 relevant chunks\n",
      "Correct answers: 3/10\n",
      "Current average score: 0.6439\n",
      "Document chunked into 22 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.6500\n",
      "Document chunked into 14 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 3 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.6508\n",
      "Non valid projects: 0\n"
     ]
    }
   ],
   "source": [
    "non_valid_counter = 0\n",
    "answers_score = []\n",
    "answers = []\n",
    "for call in valid_projects:\n",
    "    \n",
    "    with open(\"./test_data/\"+call+\"_questions_answers.txt\", \"r\") as file:\n",
    "        input = file.read()\n",
    "        try:\n",
    "            question_and_answers = json.loads(input)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    with open(\"./data\"+\"/\"+call+\"_combined_text.txt\", \"r\") as file:\n",
    "        input_combined = file.read()\n",
    "    \n",
    "    # Step 1: Chunk the combined text\n",
    "    chunks = chunk_text(input_combined)\n",
    "    print(f\"Document chunked into {len(chunks)} pieces\")\n",
    "    \n",
    "    # Step 2: Vectorize all chunks with E5 multilingual model\n",
    "    chunk_embeddings = model.encode(chunks)\n",
    "    print(\"All chunks vectorized\")\n",
    "    \n",
    "    # Step 3: Extract questions\n",
    "    questions = [question[\"question\"] for question in question_and_answers[\"test_questions\"]]\n",
    "    original_answers = [question[\"answer\"] for question in question_and_answers[\"test_questions\"]]\n",
    "    \n",
    "    # Step 4: Process each question to get relevant context\n",
    "    all_relevant_chunks = []\n",
    "    for question in questions:\n",
    "        # Vectorize the question\n",
    "        question_embedding = model.encode(question)\n",
    "        \n",
    "        # Find top 5 relevant chunks\n",
    "        top_chunks = find_top_k_chunks(question_embedding, chunk_embeddings, chunks, k=1)\n",
    "        \n",
    "        # Add to our collection (only the text, not the scores)\n",
    "        all_relevant_chunks.extend([chunk for chunk, _ in top_chunks])\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_chunks = []\n",
    "    for chunk in all_relevant_chunks:\n",
    "        if chunk not in unique_chunks:\n",
    "            unique_chunks.append(chunk)\n",
    "    \n",
    "    # Combine all relevant chunks as context\n",
    "    rag_context = \"\\n\\n\".join(unique_chunks)\n",
    "    print(f\"RAG context created with {len(unique_chunks)} relevant chunks\")\n",
    "\n",
    "    question_and_answers_blank_answers = question_and_answers.copy()\n",
    "    for question in question_and_answers_blank_answers[\"test_questions\"]:\n",
    "        question[\"answer\"] = \"TO_BE_FILLED_BY_NUMBER\"\n",
    "\n",
    "    # Use the RAG context instead of the full combined text\n",
    "    validation_answers = generate(rag_context, json.dumps(question_and_answers_blank_answers, indent=4), max_retries=5)\n",
    "    \n",
    "    validation_answers = [question[\"answer\"] for question in validation_answers[\"test_questions\"]]\n",
    "\n",
    "    correct_answers = 0\n",
    "    for i in range(len(original_answers)):\n",
    "        if str(original_answers[i]) == str(validation_answers[i]):\n",
    "            correct_answers += 1\n",
    "\n",
    "    print(f\"Correct answers: {correct_answers}/{len(original_answers)}\")\n",
    "    answers_score.append(correct_answers/len(original_answers))\n",
    "    print(f\"Current average score: {sum(answers_score)/len(answers_score):.4f}\")\n",
    "\n",
    "\n",
    "    #Save the answers to a file folder validation_single\n",
    "    if not os.path.exists(\"validation_rag\"):\n",
    "        os.makedirs(\"validation_rag\")\n",
    "    with open(f\"validation_rag/{call}_answers.json\", \"w\") as file:\n",
    "        json.dump(validation_answers, file, indent=4) \n",
    "\n",
    "    #delay\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "print(f\"Non valid projects: {non_valid_counter}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71347c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the E5 multilingual model for embedding\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "\n",
    "# Function to chunk text with overlap\n",
    "def chunk_text(text, chunk_size=512, overlap=100):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        # Create a chunk that begins at the current position\n",
    "        chunk = words[i:i + chunk_size]\n",
    "        # Join the words to form a chunk\n",
    "        chunk_text = ' '.join(chunk)\n",
    "        chunks.append(chunk_text)\n",
    "        \n",
    "        # Stop if we've processed all the words\n",
    "        if i + chunk_size >= len(words):\n",
    "            break\n",
    "            \n",
    "    return chunks\n",
    "\n",
    "# Function to find top k similar chunks\n",
    "def find_top_k_chunks(query_embedding, chunk_embeddings, chunks, k=10):\n",
    "    # Calculate similarity between query and all chunks\n",
    "    similarities = cosine_similarity([query_embedding], chunk_embeddings)[0]\n",
    "    \n",
    "    # Get indices of top k similarities\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    # Return the top k chunks and their similarity scores\n",
    "    return [(chunks[i], similarities[i]) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46906732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6508474576271186"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sum(answers_score)/len(answers_score)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a03e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
