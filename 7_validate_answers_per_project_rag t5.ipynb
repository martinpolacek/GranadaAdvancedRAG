{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c126127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['president', 'president united', 'united states', 'states', 'united']\n"
     ]
    }
   ],
   "source": [
    "# pip install keybert sentence-transformers\n",
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT(model=\"all-MiniLM-L6-v2\")  # ten samý embedding, co v RAGu\n",
    "query = \"Who is the president of the United States?\"  # dotaz, který chceme analyzovat\n",
    "\n",
    "# vytáhne top‑5 klíčových slov či frází (1–2 slova)\n",
    "keywords = kw_model.extract_keywords(\n",
    "    query,\n",
    "    keyphrase_ngram_range=(1,2),\n",
    "    stop_words='english',\n",
    "    top_n=5\n",
    ")\n",
    "print([kw for kw, score in keywords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9767724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee70d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load valid projects from valid_projects.txt\n",
    "valid_projects = []\n",
    "with open('valid_project.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        project = line.strip()\n",
    "        if project:  # Ignore empty lines\n",
    "            valid_projects.append(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1643e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import types\n",
    "import time  # Added for retry logic\n",
    "\n",
    "# Nastav API klíč (ujisti se, že máš ve svém prostředí proměnnou GOOGLE_API_KEY)\n",
    "genai.configure(api_key=\"AIzaSyB3LkpREqIq8WwCFxsjXEd6-2h-Jnu1G7U\")\n",
    "\n",
    "\n",
    "def generate(input: str, questions:str, max_retries=5):\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following text about a European Project Call answer to each question. Output must be in same JSON format. Each answer must be only a number!\n",
    "\n",
    "    Text:\n",
    "    {input}\n",
    "\n",
    "    Questions:\n",
    "    {questions}\n",
    "    \"\"\"\n",
    "\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            # Najdi první a poslední složenou závorku a zkus to zparsovat\n",
    "            json_start = response.text.find('{')\n",
    "            json_end = response.text.rfind('}') + 1\n",
    "            json_str = response.text[json_start:json_end]\n",
    "            parsed = json.loads(json_str)\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            wait_time = 2 ** retries  # Exponential backoff\n",
    "            print(f\"Retry {retries}/{max_retries} after error: {e}. Waiting {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "    print(\"Max retries reached. Returning None.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbecae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document chunked into 589 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 28 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8000\n",
      "Document chunked into 579 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 24 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8500\n",
      "Document chunked into 727 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 23 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.9000\n",
      "Document chunked into 5 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.9250\n",
      "Document chunked into 7 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 7 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.9400\n",
      "Document chunked into 591 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 25 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.9333\n",
      "Document chunked into 591 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 33 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.9000\n",
      "Document chunked into 593 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 16 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8875\n",
      "Document chunked into 592 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 24 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.9000\n",
      "Document chunked into 590 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 36 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.9000\n",
      "Document chunked into 653 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 17 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.9000\n",
      "Document chunked into 8 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 8 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.9083\n",
      "Document chunked into 243 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 28 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.9000\n",
      "Document chunked into 11 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 11 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.9071\n",
      "Document chunked into 674 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 39 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.9000\n",
      "Document chunked into 771 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 41 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.9000\n",
      "Document chunked into 767 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 47 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.8824\n",
      "Document chunked into 308 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 30 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8889\n",
      "Document chunked into 304 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 33 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8895\n",
      "Document chunked into 307 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 43 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8850\n",
      "Document chunked into 67 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 34 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8857\n",
      "Document chunked into 18 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 14 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8864\n",
      "Document chunked into 514 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 22 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.8783\n",
      "Document chunked into 599 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 17 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8833\n",
      "Document chunked into 512 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 22 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8800\n",
      "Document chunked into 913 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 60 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8769\n",
      "Document chunked into 107 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 35 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8741\n",
      "Document chunked into 735 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 65 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8714\n",
      "Document chunked into 657 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 53 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8724\n",
      "Document chunked into 656 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 40 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8700\n",
      "Document chunked into 510 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 16 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8742\n",
      "Document chunked into 576 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 38 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8719\n",
      "Document chunked into 627 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 35 relevant chunks\n",
      "Correct answers: 5/10\n",
      "Current average score: 0.8606\n",
      "Document chunked into 11 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 10 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8647\n",
      "Document chunked into 5 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 5 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8686\n",
      "Document chunked into 291 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 42 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8694\n",
      "Document chunked into 188 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 32 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8676\n",
      "Document chunked into 1134 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 56 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.8632\n",
      "Document chunked into 1206 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 48 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.8564\n",
      "Document chunked into 1148 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 58 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.8525\n",
      "Document chunked into 907 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 32 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8512\n",
      "Document chunked into 832 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 31 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.8476\n",
      "Document chunked into 169 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 18 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8488\n",
      "Document chunked into 527 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 34 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8477\n",
      "Document chunked into 593 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 49 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.8444\n",
      "Document chunked into 1 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 1 relevant chunks\n",
      "Correct answers: 1/1\n",
      "Current average score: 0.8478\n",
      "Document chunked into 130 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 33 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8468\n",
      "Document chunked into 570 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 38 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8458\n",
      "Document chunked into 567 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 24 relevant chunks\n",
      "Correct answers: 8/10\n",
      "Current average score: 0.8449\n",
      "Document chunked into 134 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 40 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8480\n",
      "Document chunked into 780 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 40 relevant chunks\n",
      "Correct answers: 3/10\n",
      "Current average score: 0.8373\n",
      "Document chunked into 664 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 37 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8385\n",
      "Document chunked into 575 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 28 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.8358\n",
      "Document chunked into 581 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 24 relevant chunks\n",
      "Correct answers: 9/10\n",
      "Current average score: 0.8370\n",
      "Document chunked into 687 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 25 relevant chunks\n",
      "Correct answers: 7/10\n",
      "Current average score: 0.8345\n",
      "Document chunked into 671 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 22 relevant chunks\n",
      "Correct answers: 6/10\n",
      "Current average score: 0.8304\n",
      "Document chunked into 659 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 30 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8333\n",
      "Document chunked into 22 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 14 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8362\n",
      "Document chunked into 14 pieces\n",
      "All chunks vectorized\n",
      "RAG context created with 12 relevant chunks\n",
      "Correct answers: 10/10\n",
      "Current average score: 0.8390\n",
      "Non valid projects: 0\n"
     ]
    }
   ],
   "source": [
    "non_valid_counter = 0\n",
    "answers_score = []\n",
    "answers = []\n",
    "for call in valid_projects:\n",
    "    \n",
    "    with open(\"./test_data/\"+call+\"_questions_answers.txt\", \"r\") as file:\n",
    "        input = file.read()\n",
    "        try:\n",
    "            question_and_answers = json.loads(input)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    with open(\"./data\"+\"/\"+call+\"_combined_text.txt\", \"r\") as file:\n",
    "        input_combined = file.read()\n",
    "    \n",
    "    # Step 1: Chunk the combined text\n",
    "    chunks = chunk_text(input_combined)\n",
    "    print(f\"Document chunked into {len(chunks)} pieces\")\n",
    "    \n",
    "    # Step 2: Vectorize all chunks with E5 multilingual model\n",
    "    chunk_embeddings = model.encode(chunks)\n",
    "    print(\"All chunks vectorized\")\n",
    "    \n",
    "    # Step 3: Extract questions\n",
    "    questions = [question[\"question\"] for question in question_and_answers[\"test_questions\"]]\n",
    "    original_answers = [question[\"answer\"] for question in question_and_answers[\"test_questions\"]]\n",
    "    \n",
    "    # Step 4: Process each question to get relevant context\n",
    "    all_relevant_chunks = []\n",
    "    for question in questions:\n",
    "        # Extrahuj klíčová slova z otázky\n",
    "        keywords = kw_model.extract_keywords(\n",
    "            question,\n",
    "            keyphrase_ngram_range=(1,2),\n",
    "            stop_words='english',\n",
    "            top_n=10\n",
    "        )\n",
    "        # Spoj klíčová slova do jednoho dotazu\n",
    "        keywords_text = ' '.join([kw for kw, score in keywords])\n",
    "        # Vektorizuj pouze klíčová slova\n",
    "        question_embedding = model.encode(keywords_text)\n",
    "        \n",
    "        # Najdi nejrelevantnější chunk\n",
    "        top_chunks = find_top_k_chunks(question_embedding, chunk_embeddings, chunks, k=10)\n",
    "        \n",
    "        # Přidej do kolekce (pouze text, ne skóre)\n",
    "        all_relevant_chunks.extend([chunk for chunk, _ in top_chunks])\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_chunks = []\n",
    "    for chunk in all_relevant_chunks:\n",
    "        if chunk not in unique_chunks:\n",
    "            unique_chunks.append(chunk)\n",
    "    \n",
    "    # Combine all relevant chunks as context\n",
    "    rag_context = \"\\n\\n\".join(unique_chunks)\n",
    "    print(f\"RAG context created with {len(unique_chunks)} relevant chunks\")\n",
    "\n",
    "    question_and_answers_blank_answers = question_and_answers.copy()\n",
    "    for question in question_and_answers_blank_answers[\"test_questions\"]:\n",
    "        question[\"answer\"] = \"TO_BE_FILLED_BY_NUMBER\"\n",
    "\n",
    "    # Use the RAG context instead of the full combined text\n",
    "    validation_answers = generate(rag_context, json.dumps(question_and_answers_blank_answers, indent=4), max_retries=5)\n",
    "    \n",
    "    validation_answers = [question[\"answer\"] for question in validation_answers[\"test_questions\"]]\n",
    "\n",
    "    correct_answers = 0\n",
    "    for i in range(len(original_answers)):\n",
    "        if str(original_answers[i]) == str(validation_answers[i]):\n",
    "            correct_answers += 1\n",
    "\n",
    "    print(f\"Correct answers: {correct_answers}/{len(original_answers)}\")\n",
    "    answers_score.append(correct_answers/len(original_answers))\n",
    "    print(f\"Current average score: {sum(answers_score)/len(answers_score):.4f}\")\n",
    "\n",
    "\n",
    "    #Save the answers to a file folder validation_single\n",
    "    if not os.path.exists(\"validation_rag\"):\n",
    "        os.makedirs(\"validation_rag\")\n",
    "    with open(f\"validation_rag/{call}_answers.json\", \"w\") as file:\n",
    "        json.dump(validation_answers, file, indent=4) \n",
    "\n",
    "    #delay\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "print(f\"Non valid projects: {non_valid_counter}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71347c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the E5 multilingual model for embedding\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "\n",
    "# Function to chunk text with overlap\n",
    "def chunk_text(text, chunk_size=512, overlap=100):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        # Create a chunk that begins at the current position\n",
    "        chunk = words[i:i + chunk_size]\n",
    "        # Join the words to form a chunk\n",
    "        chunk_text = ' '.join(chunk)\n",
    "        chunks.append(chunk_text)\n",
    "        \n",
    "        # Stop if we've processed all the words\n",
    "        if i + chunk_size >= len(words):\n",
    "            break\n",
    "            \n",
    "    return chunks\n",
    "\n",
    "# Function to find top k similar chunks\n",
    "def find_top_k_chunks(query_embedding, chunk_embeddings, chunks, k=10):\n",
    "    # Calculate similarity between query and all chunks\n",
    "    similarities = cosine_similarity([query_embedding], chunk_embeddings)[0]\n",
    "    \n",
    "    # Get indices of top k similarities\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    # Return the top k chunks and their similarity scores\n",
    "    return [(chunks[i], similarities[i]) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46906732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389830508474576"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sum(answers_score)/len(answers_score)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a03e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
